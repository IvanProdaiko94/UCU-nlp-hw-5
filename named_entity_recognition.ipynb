{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implement functionality to read and process NER 2003 English Shared Task data in CoNNL file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "def read_folder(folder, ext):\n",
    "    return [\n",
    "        read_file(os.path.join(folder, filename)) for filename in sorted(os.listdir(folder)) if filename.endswith(ext)\n",
    "    ]\n",
    "\n",
    "def read_connl_to_df(folder, ext):\n",
    "    result = []\n",
    "    for txt in read_folder(folder, ext):\n",
    "        rows = []\n",
    "        for line in txt.split('\\n'):\n",
    "            row = line.split(' ')\n",
    "            rows.append(row)\n",
    "        result.append(pd.DataFrame(rows))\n",
    "    return result\n",
    "\n",
    "def set_connl_df_naming(df):\n",
    "    df.columns = ['word', 'part_of_speech', 'chunk', 'tag']\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>chunk</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>B-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>B-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word part_of_speech chunk     tag\n",
       "0       EU            NNP  B-NP   B-ORG\n",
       "1  rejects            VBZ  B-VP       O\n",
       "2   German             JJ  B-NP  B-MISC\n",
       "3     call             NN  I-NP       O\n",
       "4       to             TO  B-VP       O"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev, test, train = [set_connl_df_naming(df.iloc[2:]) for df in read_connl_to_df('./dataset/', '.txt')]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implement 3 strategies for loading the embeddings\n",
    "\n",
    "1) load the embeddings for original capitalization of words. If embedding for this word doesn’t exists, associate it with UNKNOWN embedding (5% of score).\n",
    "\n",
    "2) load the embeddings for lowercased capitalization of words. If embedding for this lowercased word doesn’t exists, associate it with UNKNOWN embedding (5% of score).\n",
    "\n",
    "3) load the embeddings for original capitalization of words. If embedding for this word doesn’t exists, try to find the embedding for lowercased version and associate it to the word with original capitalization. Otherwise, associate it with UNKNOWN embedding (20% of score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec('./glove.6B.100d.txt', word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2V:\n",
    "    def __init__(self, w2v):\n",
    "        self.w2v = w2v\n",
    "    \n",
    "    def get_vector(self, word):\n",
    "        try:\n",
    "            return self.w2v.get_vector(word)\n",
    "        except KeyError:\n",
    "            return self.w2v.get_vector(\"unk\")\n",
    "        \n",
    "    def get_vector_lowercased(self, word):\n",
    "        try:\n",
    "            return self.w2v.get_vector(word.lower())\n",
    "        except KeyError:\n",
    "            return self.w2v.get_vector(\"unk\")\n",
    "        \n",
    "    def get_vector_lowercased_onfail(self, word):\n",
    "        unk = self.w2v.get_vector(\"unk\")\n",
    "        original_case = self.get_vector(word)\n",
    "        \n",
    "        if np.array_equal(unk, original_case):\n",
    "            return self.get_vector_lowercased(word)\n",
    "        \n",
    "        return original_case\n",
    "    \n",
    "    def enreach_df_with_vector_representation_of_words(self, df, col_in, col_out):\n",
    "        df[col_out] = df[col_in].apply(lambda word: self.get_vector_lowercased_onfail(word))\n",
    "        return df\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_word2vec_format(path):\n",
    "        embeddings = KeyedVectors.load_word2vec_format(path)\n",
    "        return W2V(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = W2V.load_word2vec_format(word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev, test, train = [glove.enreach_df_with_vector_representation_of_words(df, \"word\", \"vec\") for df in [dev, test, train]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>chunk</th>\n",
       "      <th>tag</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>[-0.32714, 0.082503, 1.2561, 0.24888, 0.066019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>B-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>[0.013857, 0.70729, 0.81856, 0.8307, 0.063785,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>[0.50719, 0.53343, 0.20154, 0.67101, -0.3352, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>[-0.57833, -0.0036551, 0.34658, -0.13135, -0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>B-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>[-0.1897, 0.050024, 0.19084, -0.049184, -0.089...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word part_of_speech chunk     tag  \\\n",
       "0       EU            NNP  B-NP   B-ORG   \n",
       "1  rejects            VBZ  B-VP       O   \n",
       "2   German             JJ  B-NP  B-MISC   \n",
       "3     call             NN  I-NP       O   \n",
       "4       to             TO  B-VP       O   \n",
       "\n",
       "                                                 vec  \n",
       "0  [-0.32714, 0.082503, 1.2561, 0.24888, 0.066019...  \n",
       "1  [0.013857, 0.70729, 0.81856, 0.8307, 0.063785,...  \n",
       "2  [0.50719, 0.53343, 0.20154, 0.67101, -0.3352, ...  \n",
       "3  [-0.57833, -0.0036551, 0.34658, -0.13135, -0.5...  \n",
       "4  [-0.1897, 0.050024, 0.19084, -0.049184, -0.089...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implement training on batches (20% of score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Implement the calculation of token-level Precision / Recall / F1 / F0.5 scores for all classes in average. IMPORTANT! Please, imple- ment “micro-average” approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provide the report the performances (F1 and F0.5 scores) on the dev / test subsets w.r.t epoch number during the training for the first 5 epochs for each strategy of loading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
